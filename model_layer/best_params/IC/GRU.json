 {
     "epochs": 10,
     "batch_size": 128,
     "hidden_size": 128,
     "seq_length": 8,
     "weight_decay": 0.0028780633371441426,
     "num_layers": 1,
     "fc_size": 32,
     "learning_rate": 0.003468997588562518,
     "dropout_prob": 0.17088626278010194
 }